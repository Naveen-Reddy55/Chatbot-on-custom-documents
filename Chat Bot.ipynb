{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd578162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import openai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import chromadb\n",
    "from  PyPDF2 import PdfReader\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.callbacks.base import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chains import (\n",
    "    ConversationalRetrievalChain,\n",
    "    LLMChain\n",
    ")\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.vectorstores import Chroma\n",
    "import keyboard\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ee04d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY']=''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20b2a511",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_vector_store(folder_path):\n",
    "    \n",
    "    openai_key=os.environ['OPENAI_API_KEY']\n",
    "    all_text=[]\n",
    "\n",
    "    for i in os.listdir(folder_path):\n",
    "        filename=os.path.join(str(folder_path),i)\n",
    "        if filename.endswith('.pdf'):\n",
    "            reader = PdfReader(filename)\n",
    "            page_texts = [page.extract_text() for page in reader.pages]\n",
    "            text = \" \".join(page_texts)\n",
    "            all_text.append(text)\n",
    "\n",
    "        elif filename.endswith('.txt'):\n",
    "            with open(filename, encoding=\"utf8\") as f:\n",
    "                all_text.append(f.read())\n",
    "\n",
    "\n",
    "    documentation_text=\"/n\".join(all_text)\n",
    "    text_splitter =  CharacterTextSplitter(\n",
    "        separator='\\n',\n",
    "        chunk_overlap=0,\n",
    "        chunk_size=600\n",
    "    )\n",
    "\n",
    "    texts = text_splitter.create_documents([documentation_text])\n",
    "    texts=[doc.page_content for doc in texts]\n",
    "\n",
    "    embedding = OpenAIEmbeddings()\n",
    "\n",
    "    vector_store=Chroma.from_texts(\n",
    "      texts=texts,\n",
    "      embedding=embedding,\n",
    "      persist_directory=r'C:\\Users\\Naveen Reddy\\Downloads\\chatbot', \n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06499eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_chat_bot():\n",
    "    \n",
    "    chat_history=[]\n",
    "    \n",
    "    embedding = OpenAIEmbeddings()\n",
    "\n",
    "    \n",
    "    vectordb = Chroma(persist_directory=r'C:\\Users\\Naveen Reddy\\Downloads\\chatbot', embedding_function=embedding)\n",
    "\n",
    "    template = \"\"\"Given the following chat history and a follow up question, rephrase the follow up input question to be a standalone question.\n",
    "    Or end the conversation if it seems like it's done.\n",
    "    Chat History:\\\"\"\"\n",
    "    {chat_history}\n",
    "    \\\"\"\"\n",
    "    Follow Up Input: \\\"\"\"\n",
    "    {question}\n",
    "    \\\"\"\"\n",
    "    Standalone question:\"\"\"\n",
    "\n",
    "    condense_question_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "    # [Prompt]\n",
    "    prompt_template = \"\"\"You are a Bot assistant answering any questions about support queries for hyperverge company.\n",
    "    You are given a question and a set of information and carefully observe the information provided because the clients ask some tricky questions.\n",
    "    If the user's question requires you to provide specific information from the information, give your answer based only on the examples provided below. DON'T generate an answer that is NOT written in the provided examples.\n",
    "    If you don't find the answer to the user's question with the examples provided to you below, answer that you didn't find the answer in the documentation and propose him to rephrase his query with more details.\n",
    "    Use bullet points if you have to make a list, only if necessary.\n",
    "\n",
    "    QUESTION: {question}\n",
    "\n",
    "    DOCUMENTS:\n",
    "    =========\n",
    "    {context}\n",
    "    =========\n",
    "    Finish by proposing your help for anything else.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    qa_prompt= PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "    llm = OpenAI(temperature=0)\n",
    "\n",
    "    streaming_llm = OpenAI(\n",
    "        streaming=True,\n",
    "        callback_manager=CallbackManager([\n",
    "            StreamingStdOutCallbackHandler()\n",
    "        ]),\n",
    "        verbose=True,\n",
    "        max_tokens=250,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    question_generator = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=condense_question_prompt\n",
    "    )\n",
    "\n",
    "    doc_chain = load_qa_chain(\n",
    "    llm=streaming_llm,\n",
    "    chain_type=\"stuff\",\n",
    "    prompt=qa_prompt\n",
    "    )\n",
    "\n",
    "    chatbot = ConversationalRetrievalChain(\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    combine_docs_chain=doc_chain,\n",
    "    question_generator=question_generator,\n",
    "    )\n",
    "\n",
    "\n",
    "    question = input(\"Hi! What are you looking for today?\")\n",
    "    chat_history\n",
    "    while True:\n",
    "        result = chatbot(\n",
    "            {\"question\": question, \"chat_history\": chat_history}\n",
    "        )\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "        chat_history.append((result[\"question\"], result[\"answer\"]))\n",
    "        if keyboard.is_pressed('q'):  \n",
    "            break\n",
    "\n",
    "        question = input()\n",
    "        if question.lower() in ['exit', 'quit']:\n",
    "            print(\"Thank you for contacting support...\")\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f5dd676",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: C:\\Users\\Naveen Reddy\\Downloads\\chatbot\n"
     ]
    }
   ],
   "source": [
    "folder_path=r'C:\\Users\\Naveen Reddy\\Downloads\\chatbot\\Documentation\\Documentation'\n",
    "get_vector_store(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8627cc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: C:\\Users\\Naveen Reddy\\Downloads\\chatbot\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! What are you looking for today?hi\n",
      "\n",
      "Sorry, I didn't understand your question. Could you please rephrase it with more details? If you need help with anything else, please let me know.\n",
      "\n",
      "what is hyperverge api\n",
      "\n",
      "Answer: The Hyperverge API is a REST-based API that uses standard HTTP verbs and status codes. It uses JSON format for requests and responses and requires authentication with an AppID and AppKey. It provides access to HyperVerge and your team for debugging various issues that might have occurred during AI processing. It also includes a Liveness API, Score Based Name Match API, and Field Match API. The Score Based Name Match API can be used to compare a name from one source with the same name from another source, and we consider initials in a name to be 2 or lesser characters.\n",
      "\n",
      "Is there anything else I can help you with?\n",
      "\n",
      "what liveness api\n",
      "\n",
      "Answer: The Liveness API is a proprietary API from HyperVerge that is used to ascertain if an image of a user is not a photo of a photo (not live). It supports jpeg, png and tiff images and requires the image to be a portrait. It also requires HTTPS for all API access and data is received as JSON. Additionally, image uploads must be performed as form-data (POST request).\n",
      "\n",
      "does hyperverge support vietnam\n",
      "\n",
      "Unfortunately, I cannot answer your question as the provided information does not mention anything about Hyperverge's support for Vietnam. Kindly reach out to Hyperverge Integrations Team for more information. Is there anything else I can help you with?\n",
      "\n",
      "i having issue with sdk download, seems like there is an error with aws\n",
      "\n",
      "Answer: It looks like you are facing an error while downloading the Hyperverge SDK from AWS. According to the documentation, the possible errors that the API can return are: \n",
      "\n",
      "1. HTTP Status Code 400 is returned for request errors.\n",
      "2. HTTP Status code 404 is returned when there is an error from CERSAI repository.\n",
      "3. “error”: { “code”: “ER_CKYC_SEARCH_AND_DOWNLOAD”, “message” : “<IP_No> : IP does not match with IP registered on CKYCRR portal” }\n",
      "4. { \"status\" : \"failure\" , \"statusCode\" : \"401\", \"error\": \"Missing/Invalid credentials\" }\n",
      "5. { “status” : “failure” , “statusCode” : “500”, “error”: { “code”: “ER_SERVER” , “message” :"
     ]
    }
   ],
   "source": [
    "run_chat_bot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2427375",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
